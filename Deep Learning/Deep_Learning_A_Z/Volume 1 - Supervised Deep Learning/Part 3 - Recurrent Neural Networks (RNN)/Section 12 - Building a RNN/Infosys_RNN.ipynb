{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1 Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_File_Path = 'Infosys_RNN_Model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Dataset_File_Path = r'E.csv'\n",
    "dataset_train = pd.read_csv(train_Dataset_File_Path)\n",
    "\n",
    "training_set = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "training_set_Scaled = sc.fit_transform(training_set)\n",
    "\n",
    "print (len(training_set_Scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a data structure with 60 timesteps and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_Step = 60\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range (time_Step, len(training_set_Scaled)):\n",
    "    X_train.append(training_set_Scaled[i-time_Step: i, 0])\n",
    "    y_train.append(training_set_Scaled[i,0])\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "    \n",
    "# print (X_train)\n",
    "# print (y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-2 Building RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import lstm, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1) ))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, ))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, ))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50 ))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "555/555 [==============================] - 7s 12ms/step - loss: 0.1209\n",
      "Epoch 2/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0167\n",
      "Epoch 3/10\n",
      "555/555 [==============================] - 2s 4ms/step - loss: 0.0072\n",
      "Epoch 4/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0045\n",
      "Epoch 5/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0044\n",
      "Epoch 6/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0040\n",
      "Epoch 7/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0036\n",
      "Epoch 8/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0034\n",
      "Epoch 10/10\n",
      "555/555 [==============================] - 2s 3ms/step - loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2293de72860>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor.save(model_File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = load_model(model_File_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 1)\n"
     ]
    }
   ],
   "source": [
    "test_Dataset_File_Path = r'F.csv'\n",
    "dataset_test = pd.read_csv(test_Dataset_File_Path)\n",
    "# print (type(dataset_test))\n",
    "real_stock_price = dataset_test.iloc[:,1:2].values\n",
    "print ((real_stock_price.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total = (dataset_train['Open Price'])\n",
    "# print (type(dataset_total))\n",
    "inputs = dataset_total[len(dataset_total) - time_Step : ].values\n",
    "# print ((inputs.shape))\n",
    "inputs = inputs.reshape(-1,1)\n",
    "# print ((inputs.shape))\n",
    "inputs = sc.transform(inputs)\n",
    "# print ((inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(50,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-b74b45f786ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "\n",
    "for i in range (time_Step, 110):\n",
    "#     print (type(inputs[i-time_Step: i, 0]))\n",
    "    X_test.append(inputs[i-time_Step: i, 0])\n",
    "\n",
    "print(type(X_test))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "print((X_test.shape))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1) )\n",
    "\n",
    "print((X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Stock_Price = regressor.predict(X_test)\n",
    "predicted_Stock_Price = sc.inverse_transform(predicted_Stock_Price)\n",
    "\n",
    "# print ((predicted_Stock_Price))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-941daee14205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# predicted_Stock_Price = sc.inverse_transform(predicted_Stock_Price)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_last_60_days\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_Stock_Price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\product\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scale_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\product\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 451\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# Predicting Stock price for next 100 days\n",
    "\n",
    "future_Time_Steps = 100\n",
    "data_last_60_days=[]\n",
    "data_append_next_Prediction = 0\n",
    "\n",
    "for i in range(len(dataset_test) - time_Step , len(dataset_test)):\n",
    "    data_last_60_days.append((dataset_test.iloc[i,1]))\n",
    "     \n",
    "\n",
    "data_append_next_Prediction = data_last_60_days\n",
    "data_last_60_days = np.array(data_last_60_days)\n",
    "data_last_60_days = np.reshape(data_last_60_days, (time_Step, 1))\n",
    "\n",
    "data_last_60_days = sc.transform(data_last_60_days)\n",
    "\n",
    "print ((data_last_60_days.shape))\n",
    "\n",
    "\n",
    "temp = []\n",
    "temp.append(data_last_60_days[0:time_Step,0])\n",
    "\n",
    "data_last_60_days = np.array(temp)\n",
    "# print((data_last_60_days.shape))\n",
    "\n",
    "data_last_60_days = np.reshape(data_last_60_days, (1, time_Step, 1) )\n",
    "# print((data_last_60_days.shape))\n",
    "\n",
    "\n",
    "\n",
    "predicted_Stock_Price = regressor.predict(data_last_60_days)\n",
    "# predicted_Stock_Price = sc.inverse_transform(predicted_Stock_Price)\n",
    "\n",
    "print(sc.inverse_transform(data_last_60_days))\n",
    "print ((predicted_Stock_Price[0][0]))\n",
    "\n",
    "\n",
    "\n",
    "for i in range (0,future_Time_Steps):\n",
    "    data_append_next_Prediction.append(predicted_Stock_Price[0][0])\n",
    "    \n",
    "    data_last_60_days = []\n",
    "    for i in range (len(data_append_next_Prediction) - time_Step, len(data_append_next_Prediction)):\n",
    "        data_last_60_days.append(data_append_next_Prediction[i])\n",
    "        \n",
    "    data_append_next_Prediction = data_last_60_days\n",
    "    data_last_60_days = np.array(data_last_60_days)\n",
    "    data_last_60_days = np.reshape(data_last_60_days, (time_Step, 1))\n",
    "\n",
    "    data_last_60_days = sc.transform(data_last_60_days)\n",
    "\n",
    "#     print ((data_last_60_days.shape))\n",
    "\n",
    "\n",
    "    temp = []\n",
    "    temp.append(data_last_60_days[0:60,0])\n",
    "\n",
    "    data_last_60_days = np.array(temp)\n",
    "#     print((data_last_60_days.shape))\n",
    "\n",
    "    data_last_60_days = np.reshape(data_last_60_days, (1, time_Step, 1) )\n",
    "#     print((data_last_60_days.shape))\n",
    "\n",
    "\n",
    "\n",
    "    predicted_Stock_Price = regressor.predict(data_last_60_days)\n",
    "    predicted_Stock_Price = sc.inverse_transform(predicted_Stock_Price)\n",
    "\n",
    "#     print ((predicted_Stock_Price[0][0]))\n",
    "\n",
    "\n",
    "print ((data_append_next_Prediction) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_stock_price , color = 'red', label = 'Real Infosys Stock Price')\n",
    "plt.plot(predicted_Stock_Price , color = 'blue', label = 'Predicted Infosys Stock Price')\n",
    "plt.title('Stock Price')\n",
    "plt.xlabel('Time In Days')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
